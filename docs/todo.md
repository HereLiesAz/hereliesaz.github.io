Version: 1.0
Objective: Construct an infinite, procedurally generated 3D web portfolio where navigation is driven by pareidolia and anamorphic optical illusions.1. System Architecture OverviewThe system consists of two distinct components:The Curator (Offline Python Pipeline): A computer vision engine that ingests raw artwork, decomposes it into semantic "shards," maps depth, and builds a graph of visual similarities (pareidolia connections).The Viewer (Frontend WebGL Application): A React Three Fiber (R3F) runtime that procedurally generates a camera path through an infinite void, using the Curator's data to align scattered 3D shards into coherent 2D images at specific perspective points.Technology StackFrontend: Next.js, React Three Fiber (R3F), Three.js, GLSL (Custom Shaders), Zustand (State).Asset Pipeline: Python 3.10+, PyTorch, Segment Anything Model (SAM), ZoeDepth, DINOv2, OpenCV.Data Format: glTF (Draco compressed) for geometry, KTX2 for textures, JSON for graph relationships.2. Phase 1: The Curator (Asset Processing Pipeline)Agent Goal: Create a Python script (curator.py) that processes a folder of images into game-ready assets and a navigation graph.2.1. Step 1: Semantic Decomposition (The "Shards")Instead of cutting images into grid tiles, we must cut them along artistic strokes.Algorithm: Use Segment Anything Model (SAM) in "automatic mask generation" mode.Parameters:points_per_side: 32 (High density)pred_iou_thresh: 0.88 (Ensure high coherence)stability_score_thresh: 0.95Output: A collection of binary masks for each image.Post-Processing:Convert masks to vector contours (OpenCV findContours).Triangulate contours into 3D-compatible flat meshes (Delaunay Triangulation).Crucial: Assign a unique shard_id to each mesh.2.2. Step 2: Depth Injection (The "World")For murals and paintings with depth, we need to place shards at correct Z-depths relative to each other.Algorithm: ZoeDepth (Metric Depth Estimation).Process:Run inference on the source image to get a 16-bit depth map.For each "Shard" (from Step 2.1), calculate the average depth intensity of pixels within its mask.Assign this depth value ($z_{local}$) to the shard's geometry.2.3. Step 3: The Pareidolia Graph (The "Fulcrum")We need to find "accidental matches" between different paintings to serve as transition points.Feature Extraction: Use DINOv2 (ViT-L/14) to extract patch-level embeddings for every shard.Pareidolia Detection:Run a standard object detector (YOLO or fine-tuned DINO head) on the abstract shards.If a cloud shard is detected as a "face" with low confidence (0.3 - 0.6), flag it as a Pareidolia Anchor.Graph Construction:Build a similarity matrix comparing all shards in the library.Edge Creation: Create a directed edge from Image A to Image B if a shard in A (e.g., "cloud") has a cosine similarity $> 0.85$ with a shard in B (e.g., "actual face").Output: graph.json containing nodes (images) and weighted edges (transitions).2.4. Asset PackagingTexture Arrays: To minimize draw calls, pack all shard textures into WEBGL_texture_array. Do not use standard atlases (to avoid bleeding).Instancing: Export a single InstancedMesh definition where instance attributes (position, scale, rotation, UVs) are stored in binary .bin files.3. Phase 2: The Viewer (Frontend Runtime)Agent Goal: Initialize a Next.js/R3F application that loads the graph.json and procedurally generates the scroll experience.3.1. The Anamorphic Math (The "Reveal")The core mechanic is Forced Perspective. Shards must look scattered/chaotic from the side but align perfectly from a specific camera vector.Algorithm: Inverse Projection
For every shard $S$ in a target painting $P$:Define a Solution Viewpoint camera matrix ($V_{sol}$, $P_{sol}$).Define the shard's 2D position $(x_{2d}, y_{2d})$ on the canvas.Assign a random (or depth-map derived) distance $d$ from the camera.Calculate 3D position $P_{3d}$ by un-projecting the 2D coordinate:$$P_{3d} = V_{sol}^{-1} \cdot P_{sol}^{-1} \cdot (x_{2d}, y_{2d}, d)$$Scale Compensation: Scale the shard by $d / f$ (where $f$ is focal length) so it maintains its apparent 2D size regardless of depth.Implementation Note: This logic runs in the Vertex Shader to allow for dynamic reshuffling.3.2. Navigation Logic: The Stochastic WalkerThe user doesn't choose the path; the system does.State: CurrentNode, VisitedNodes.Next Node Selection:Get neighbors of CurrentNode from graph.json.Filter out nodes in VisitedNodes.Pareidolia Bias: Prioritize neighbors where the transition edge matches the shard the user is currently hovering over (Mouse Raycast).If no hover, select neighbor using weighted probability (favor visual similarity).3.3. The Transition: "The Unnerving Reveal"Do not use CSS opacity. Use a Noise-Discard Shader.Vertex Shader:Interpolate shard positions from Random_State (Chaos) to Aligned_State (Order).Driven by a uScrollProgress uniform.Fragment Shader (The Dissolve):Use a 3D Perlin noise texture.Logic:OpenGL Shading Languagefloat noise = texture(uNoiseMap, vUv + uTime).r;
float visibility = smoothstep(uThreshold - 0.1, uThreshold, noise);
if (visibility < 0.01) discard; // Hard cut, no soft fade
Visual Effect: As uThreshold changes, the previous painting burns away or crumbles into nothingness, revealing the next painting's shards which were already floating behind it, aligned to the camera.4. Implementation Steps for AgentRepo Init:npx create-next-app@latest portfolio --typescriptnpm install three @react-three/fiber @react-three/drei leva zustand uuidpip install torch torchvision opencv-python segment-anything zoedepth transformersBackend (Run once):Create scripts/process_art.py.Implement SAM predictor to slice images.Implement ZoeDepth to assign Z-values.Implement DINOv2 to generate similarity_graph.json.Frontend Core:Create components/Scene.tsx: Setup R3F Canvas.Create components/AnamorphicCam.tsx: Custom camera controller that interpolates along a Catmull-Rom spline between "Solution Points."Create shaders/ShardMaterial.ts: Custom ShaderMaterial with uProgress and uResolution uniforms.Interaction:Implement useScroll from @react-three/drei.Map scroll delta to camera movement along the spline.Trigger "Graph Traversal" when scroll reaches the end of the current spline segment.5. Design Constraints & RulesNo Liquid/Morphing: Transitions must be rigid. Shards fly into place or dissolve.Hidden in Plain Sight: When looking at Painting A, the shards for Painting B must be present in the background (as "stars" or "dust") but unaligned. They only form Painting B when the camera rotates to the specific angle.Always Forward: Scrolling up does not go "back" in history; it reverses the camera on the current spline, but once a transition threshold is crossed, the previous painting is discarded from memory.6. Prompt for Agent ExecutionCopy and paste this into your IDE agent (e.g., Cursor, GitHub Copilot Workspace) to start:"Act as a Senior Creative Technologist. We are building a React Three Fiber web portfolio. First, set up the Python pipeline to process a folder of images. Use Segment Anything Model to generate masks for each image, identifying distinct brush strokes or objects. Save each segment as a polygon in a JSON file. Then, use ZoeDepth to generate a depth map for each image and assign a relative Z-depth to each segment. Finally, create a JSON graph linking images based on color palette similarity. Do not build the frontend yet; focus on the data processing pipeline."
